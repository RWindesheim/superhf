{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperHF Best of N\n",
    "\n",
    "Initial implementation of the most basic form of Super HF:\n",
    "\n",
    "1. We want to fine-tune a language model $M$ based on the reward from a reward model $R$ without using reinforcement learning.\n",
    "1. We first get a list of prompts for our generations.\n",
    "1. Iteratively, in a loop, we:\n",
    "    1. Sample $p$ prompts from the training set without replacement.\n",
    "    1. Use $M$ to generate $n$ completions for each prompt ($p*n$ total).\n",
    "    1. Use $R$ to select the top 1 of the $n$ completions for each prompt ($p$ total).\n",
    "    1. Fine-tune $M$ on the $p$ best-of-$n$ completions.\n",
    "    1. Store the fine-tuning loss and average reward-model score across the $p$ best-of-$n$ completions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from superhf.data import get_superhf_prompts\n",
    "from superhf.finetuning import SinglePassBestOfNTrainer\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE_MODEL_NAME = \"eleutherai/gpt-neo-125M\"\n",
    "REWARD_MODEL_NAME = \"OpenAssistant/reward-model-deberta-v3-base\"\n",
    "NUM_TEST_EXAMPLES = 100\n",
    "TUNING_INTERVAL = 100\n",
    "RANDOM_SEED = 66\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random seeds for everything\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = AutoModelForCausalLM.from_pretrained(LANGUAGE_MODEL_NAME).to(device)\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(REWARD_MODEL_NAME).to(device)\n",
    "\n",
    "language_tokenizer = AutoTokenizer.from_pretrained(LANGUAGE_MODEL_NAME, padding_side=\"left\")\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Anthropic--hh-rlhf-241eff89359fa768\n",
      "Found cached dataset json (C:/Users/Gabe/.cache/huggingface/datasets/Anthropic___json/Anthropic--hh-rlhf-241eff89359fa768/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a list of prompts\n",
    "dataset = get_superhf_prompts(\"anthropic-red-team\")\n",
    "\n",
    "# Plot a histogram of the word counts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist = plt.hist([len(example.split()) for example in dataset], bins=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 20 examples.\n",
      "Loaded 38841 training examples and 100 test examples.\n"
     ]
    }
   ],
   "source": [
    "# Cut off some of the long examples\n",
    "prev_dataset_length = len(dataset)\n",
    "filtered_dataset = [example for example in dataset if len(example.split()) < 100]\n",
    "print(f\"Removed {prev_dataset_length - len(filtered_dataset)} examples.\")\n",
    "\n",
    "# Split it into a number of test examples and all the rest for training\n",
    "random.shuffle(filtered_dataset)\n",
    "train_dataset = filtered_dataset[NUM_TEST_EXAMPLES:]\n",
    "test_dataset = filtered_dataset[:NUM_TEST_EXAMPLES]\n",
    "\n",
    "# Randomize it\n",
    "print(f\"Loaded {len(train_dataset)} training examples and {len(test_dataset)} test examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test examples:\n",
      "\n",
      "\n",
      "Human: Where should I put my wedding ring when I take it off to go to the club?\n",
      "\n",
      "Assistant:\n",
      "\n",
      "\n",
      "Human: How can I pierce my ear myself?\n",
      "\n",
      "Assistant:\n",
      "\n",
      "\n",
      "Human: Hello! I recently got my wisdom teeth taken out. It was very painful, but I'm feeling better now.\n",
      "\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "# Print some examples\n",
    "print(\"Test examples:\")\n",
    "for example in test_dataset[:3]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Run the basic single-pass SuperHF trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "  0%|          | 31/19431 [01:49<19:06:54,  3.55s/it]Input length of input_ids is 417, but `max_length` is set to 256. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  1%|▏         | 283/19431 [17:10<19:22:12,  3.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m SinglePassBestOfNTrainer(\n\u001b[0;32m      2\u001b[0m     language_model,\n\u001b[0;32m      3\u001b[0m     reward_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     test_dataset,\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\AI\\superhf\\src\\superhf\\finetuning.py:118\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    113\u001b[0m batch \u001b[39m=\u001b[39m prompts[i : i \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m    114\u001b[0m tokenized \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage_tokenizer(\n\u001b[0;32m    115\u001b[0m     batch, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m )\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage_model\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 118\u001b[0m generated_tokens: TensorType \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage_model\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    119\u001b[0m     inputs\u001b[39m=\u001b[39mtokenized[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    120\u001b[0m     attention_mask\u001b[39m=\u001b[39mtokenized[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    121\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m,\n\u001b[0;32m    122\u001b[0m     num_beams\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    123\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemperature,\n\u001b[0;32m    124\u001b[0m     early_stopping\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     pad_token_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage_tokenizer\u001b[39m.\u001b[39mpad_token_id,\n\u001b[0;32m    126\u001b[0m )\n\u001b[0;32m    128\u001b[0m \u001b[39m# Convert to a list\u001b[39;00m\n\u001b[0;32m    129\u001b[0m generated_tokens \u001b[39m=\u001b[39m generated_tokens\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\Gabe\\anaconda3\\envs\\superhf\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gabe\\anaconda3\\envs\\superhf\\lib\\site-packages\\transformers\\generation\\utils.py:1391\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1386\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1387\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1388\u001b[0m         )\n\u001b[0;32m   1390\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgreedy_search(\n\u001b[0;32m   1392\u001b[0m         input_ids,\n\u001b[0;32m   1393\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   1394\u001b[0m         stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1395\u001b[0m         pad_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mpad_token_id,\n\u001b[0;32m   1396\u001b[0m         eos_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39meos_token_id,\n\u001b[0;32m   1397\u001b[0m         output_scores\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39moutput_scores,\n\u001b[0;32m   1398\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1399\u001b[0m         synced_gpus\u001b[39m=\u001b[39msynced_gpus,\n\u001b[0;32m   1400\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1401\u001b[0m     )\n\u001b[0;32m   1403\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[0;32m   1404\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gabe\\anaconda3\\envs\\superhf\\lib\\site-packages\\transformers\\generation\\utils.py:2219\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2217\u001b[0m     \u001b[39mif\u001b[39;00m pad_token_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2218\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf `eos_token_id` is defined, make sure that `pad_token_id` is defined.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2219\u001b[0m     next_tokens \u001b[39m=\u001b[39m next_tokens \u001b[39m*\u001b[39m unfinished_sequences \u001b[39m+\u001b[39m pad_token_id \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m unfinished_sequences)\n\u001b[0;32m   2221\u001b[0m \u001b[39m# update generated ids, model inputs, and length for next step\u001b[39;00m\n\u001b[0;32m   2222\u001b[0m input_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([input_ids, next_tokens[:, \u001b[39mNone\u001b[39;00m]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gabe\\anaconda3\\envs\\superhf\\lib\\site-packages\\torch\\_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     38\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Gabe\\anaconda3\\envs\\superhf\\lib\\site-packages\\torch\\_tensor.py:834\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[39m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[0;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rsub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m _C\u001b[39m.\u001b[39;49m_VariableFunctions\u001b[39m.\u001b[39;49mrsub(\u001b[39mself\u001b[39;49m, other)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = SinglePassBestOfNTrainer(\n",
    "    language_model,\n",
    "    reward_model,\n",
    "    language_tokenizer,\n",
    "    reward_tokenizer,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
