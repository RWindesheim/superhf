{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c53e61b-886f-43bd-9072-e241d99aef21",
   "metadata": {},
   "source": [
    "### Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42de834b-aa80-4c19-a1f1-1a16a9a0b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fee6b7-7667-4eea-8978-b7137c21088f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7cbf85a",
   "metadata": {},
   "source": [
    "Following the guide from https://huggingface.co/docs/transformers/tasks/language_modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1400a9-a59d-476a-afda-c91e69b23fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superhf import skeleton\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, GPTNeoForCausalLM\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cdbd45a",
   "metadata": {},
   "source": [
    "## Load the Models\n",
    "1. Reward Model = (DeBERTa-v3-base (~730mb)\n",
    "2. SuperHF Model = GPT-Neo-1.3B (~1.3gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83176919",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_name = \"OpenAssistant/reward-model-deberta-v3-base\"\n",
    "reward_model, reward_tokenizer = AutoModelForSequenceClassification.from_pretrained(reward_name), AutoTokenizer.from_pretrained(reward_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "assistant_model = GPTNeoForCausalLM.from_pretrained(assistant_name)\n",
    "assistant_tokenizer = AutoTokenizer.from_pretrained(assistant_name)\n",
    "# this is the gpt2 tokenizer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check GPT-Neo-1.3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientists discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "The discovery was made by scientists from the Universidad Nacional Mayor de San Miguel, in Colombia, led by Dr. Martin Parra from the Universidad de los Andes. The scientists found that the unicorns had a common ancestor and were descended from another\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \"\n",
    "    \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \"\n",
    "    \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    ")\n",
    "input_ids = assistant_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "gen_tokens = assistant_model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = assistant_tokenizer.batch_decode(gen_tokens)[0]\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_output_from_test = \"This rare valley, which is called the Uyuni City, is located some 250 miles north of the city of Cuzco, Peru. The city of Uyuni stands on the slopes of the mountain with a population of about 1,000 people\"\n",
    "second_output_from_test = \"I am a lover of all things unicorn, and in my personal experience, unicorns are truly beautiful animals. \\n In my personal experiences, they are just as beautiful as other animals. \\n I am here to learn more about all of these animals, but we all need to talk\"\n",
    "third_output_from_test = \"The study was published today in the journal PLOS ONE. \\n The scientists discovered that the herd of unicorns had lived in the remote valley for hundreds of years. After studying three of the largest of the herd that could be spotted by the researchers, it was\"\n",
    "fourth_output_from_test = \"The discovery was made by scientists from the Universidad Nacional Mayor de San Miguel, in Colombia, led by Dr. Martin Parra from the Universidad de los Andes. The scientists found that the unicorns had a common ancestor and were descended from another\"\n",
    "# Looks like it reliably produces different outputs. Where is randomness produced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a shocking finding, scientists discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n\\nThe discovery was made by scientists from the Universidad Nacional Mayor de San Miguel, in Colombia, led by Dr. Martin Parra from the Universidad de los Andes. The scientists found that the unicorns had a common ancestor and were descended from another']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_tokenizer.batch_decode(gen_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset summarize_from_feedback (/Users/peterchatain/.cache/huggingface/datasets/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d3c3e2a7e4ba0ab3c2ecc629ab8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load webGPT comparisons dataset\n",
    "dataset_webGPT = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n",
    "# dataset_harmless = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"harmless-base\")\n",
    "# dataset = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"red-team-attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'id': 't3_ehyqt',\n",
       "  'post': \"A few months ago, I asked my RA if she wanted to participate in a fundraiser where we raced floaty toys down a river.  I asked her if she wanted to buy one because the winner won 50 dollars.  She signed up one for her and her sister.  It was her idea to buy one for her sister.  I paid for it because she didn't have cash.  Now fast forward to 2 months later, the second time I remind her that she still owes me money, and I have her rubber ducks.  I held onto the ducks until I got my money.\\n\\nShe just verbally assaulted me.  She denies ever wanting to participate in the toy race and says I pushed it on her, so I shouldn't be paid.  She was quite rude and disrespectful.  I'm calling bullshit because I would never sign someone up if they hadn't fully agreed.  It was her idea to include her sister!  \\n\\nNow she owes me 6 dollars and I'm angry.  I would have let it go despite the rudeness and disrespect.  I am now going to do everything in my power to ensure she pays me even if I have to burn down the bridge between us.  In my mind it is already half burnt.\\n\\nWhat should I do to get my rude, disrespectful and cheapskate RA to pay me the money she owes?  I'm not afraid to be mean.\",\n",
       "  'title': 'Looking for the best course of action to get my money from a rude RA.',\n",
       "  'subreddit': 'AskReddit',\n",
       "  'site': None,\n",
       "  'article': None},\n",
       " 'summaries': [{'text': \" My rude RA voluntarily participated in a fundraiser and won't pay me back.  How do I get my money?\",\n",
       "   'policy': 'ref',\n",
       "   'note': None},\n",
       "  {'text': ' RA was rude, disrespectful and cheapskate.  Now owes me a lot of money.  I want to get her to pay me back.  What should I do?',\n",
       "   'policy': 'sup1',\n",
       "   'note': None}],\n",
       " 'choice': 1,\n",
       " 'worker': 'LjvoXOAj5op3WqNnn5b7TZTG8mK7gM',\n",
       " 'batch': 'batch3',\n",
       " 'split': 'train',\n",
       " 'extra': {'confidence': None}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 3 samples from the webGPT dataset\n",
    "dataset_webGPT[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A few months ago, I asked my RA if she wanted to participate in a fundraiser where we raced floaty toys down a river.  I asked her if she wanted to buy one because the winner won 50 dollars.  She signed up one for her and her sister.  It was her idea to buy one for her sister.  I paid for it because she didn't have cash.  Now fast forward to 2 months later, the second time I remind her that she still owes me money, and I have her rubber ducks.  I held onto the ducks until I got my money.\\n\\nShe just verbally assaulted me.  She denies ever wanting to participate in the toy race and says I pushed it on her, so I shouldn't be paid.  She was quite rude and disrespectful.  I'm calling bullshit because I would never sign someone up if they hadn't fully agreed.  It was her idea to include her sister!  \\n\\nNow she owes me 6 dollars and I'm angry.  I would have let it go despite the rudeness and disrespect.  I am now going to do everything in my power to ensure she pays me even if I have to burn down the bridge between us.  In my mind it is already half burnt.\\n\\nWhat should I do to get my rude, disrespectful and cheapskate RA to pay me the money she owes?  I'm not afraid to be mean.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_webGPT[\"train\"][10]['info']['post']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate n (4) completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_completions = {\"train\": {}}\n",
    "for i in range(10):\n",
    "  sample_post = dataset_webGPT[\"train\"][i]['info']['post']\n",
    "  gpt_4_completions[\"train\"][i] = {\"prompt\": sample_post}\n",
    "  gpt_4_completions[\"train\"][i][\"completions\"] = []\n",
    "  input_ids = assistant_tokenizer(sample_post, return_tensors=\"pt\").input_ids\n",
    "  for j in range(4):\n",
    "    gen_tokens = assistant_model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        max_length=100,\n",
    "    )\n",
    "    completion = assistant_tokenizer.batch_decode(gen_tokens)[0]\n",
    "    gpt_4_completions[\"train\"][i][\"completions\"].append(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdf16676bbad4ddcd11952105f63537bbbd145d2903d460b604ae5df4d469172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
