{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trlx framework overview\n",
    "This example outline the current trlx training framework that uses a defined reward functionn. The objective of this example is to generate positive movie reviews by tuning a pretrained model on IMDB dataset with a sentiment reward function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fongsu/miniconda3/envs/multi-criteria/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "import trlx\n",
    "from trlx.data.configs import TRLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_score(scores):\n",
    "    \"Extract value associated with a positive sentiment from pipeline's output\"\n",
    "    return dict(map(lambda x: tuple(x.values()), scores))[\"POSITIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = pathlib.Path('.').joinpath(\"../configs/ppo_config.yml\")\n",
    "with open('./configs/ppo_config.yml') as f:\n",
    "    default_config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary of hparameters for overriding the config file.\n",
    "hparams = {}\n",
    "config = TRLConfig.update(default_config, hparams)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fongsu/miniconda3/envs/multi-criteria/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "else:\n",
    "    device = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_fn = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    \"lvwerra/distilbert-imdb\",\n",
    "    top_k=2,\n",
    "    truncation=True,\n",
    "    batch_size=256,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn(samples: List[str], **kwargs) -> List[float]:\n",
    "    sentiments = list(map(get_positive_score, sentiment_fn(samples)))\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/fongsu/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    }
   ],
   "source": [
    "# Take few words off of movies reviews as prompts\n",
    "imdb = load_dataset(\"imdb\", split=\"train+test\")\n",
    "prompts = [\" \".join(review.split()[:4]) for review in imdb[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 334M/334M [01:39<00:00, 3.34MB/s]\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moliversf\u001b[0m (\u001b[33mcomprehelp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fongsu/repos/superhf/src/notebooks/wandb/run-20230201_234229-xki1oh42</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/comprehelp/trlx/runs/xki1oh42\" target=\"_blank\">ipykernel_launcher/distilgpt2-finetuned-imdb-lm/1gpu:oliver</a></strong> to <a href=\"https://wandb.ai/comprehelp/trlx\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/comprehelp/trlx\" target=\"_blank\">https://wandb.ai/comprehelp/trlx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/comprehelp/trlx/runs/xki1oh42\" target=\"_blank\">https://wandb.ai/comprehelp/trlx/runs/xki1oh42</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trlx.train(\n",
    "    reward_fn=reward_fn,\n",
    "    prompts=prompts,\n",
    "    eval_prompts=[\"I don't know much about Hungarian underground\"] * 64,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1. No abstractions for reward models (Model, Trainer, Config, etc.)\n",
    "2. Low customizability for training details\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-criteria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e6bd5e7ba1b6c10a8334d53115e094ecc7f232c911209c5e7894e6bf5579750"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
